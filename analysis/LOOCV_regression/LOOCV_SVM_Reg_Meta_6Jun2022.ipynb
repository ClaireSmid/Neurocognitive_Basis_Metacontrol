{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "278d71f9",
   "metadata": {},
   "source": [
    "For this script, we used the wider set of EF measures. so we could use feature selection etc. \n",
    "This was in \"MB_EF_Detail_Reduced_Dec21\" at first. Let's use this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2c14114",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import absolute, mean, std\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import os  \n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "# https://machinelearningmastery.com/rfe-feature-selection-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30ca7baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714025946899135\n"
     ]
    }
   ],
   "source": [
    "print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f1baa34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Session</th>\n",
       "      <th>School</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age_Frac_Imp</th>\n",
       "      <th>SES_inv_z</th>\n",
       "      <th>Avg_Pts</th>\n",
       "      <th>Avg_Pts_lo</th>\n",
       "      <th>Avg_Pts_hi</th>\n",
       "      <th>w_P6</th>\n",
       "      <th>w_diff</th>\n",
       "      <th>it_P6</th>\n",
       "      <th>lr_P6</th>\n",
       "      <th>eg_P6</th>\n",
       "      <th>st_P6</th>\n",
       "      <th>repst_P6</th>\n",
       "      <th>it</th>\n",
       "      <th>lr</th>\n",
       "      <th>eg</th>\n",
       "      <th>st</th>\n",
       "      <th>repst</th>\n",
       "      <th>T_Vocab</th>\n",
       "      <th>T_Matrix</th>\n",
       "      <th>Corsi_WM_Span</th>\n",
       "      <th>CogFlex_t</th>\n",
       "      <th>SSRT</th>\n",
       "      <th>FlankerSwitch_t</th>\n",
       "      <th>FlankerInhib_t</th>\n",
       "      <th>Stroop_t</th>\n",
       "      <th>dprimeONEBACK_t0</th>\n",
       "      <th>dprimeTWOBACK_t0</th>\n",
       "      <th>AY_Inv_eff_score</th>\n",
       "      <th>BX_Inv_eff_score</th>\n",
       "      <th>CF_Mix_IES_Diff</th>\n",
       "      <th>SSRT_SSD_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Trevor Roberts School</td>\n",
       "      <td>M</td>\n",
       "      <td>12.444444</td>\n",
       "      <td>0.226732</td>\n",
       "      <td>0.013173</td>\n",
       "      <td>-0.002222</td>\n",
       "      <td>0.029551</td>\n",
       "      <td>0.425788</td>\n",
       "      <td>0.121567</td>\n",
       "      <td>0.619787</td>\n",
       "      <td>0.437227</td>\n",
       "      <td>0.419932</td>\n",
       "      <td>-0.177439</td>\n",
       "      <td>-0.709067</td>\n",
       "      <td>0.625122</td>\n",
       "      <td>0.442486</td>\n",
       "      <td>0.420558</td>\n",
       "      <td>-0.177359</td>\n",
       "      <td>-0.704026</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>0.524022</td>\n",
       "      <td>-0.798678</td>\n",
       "      <td>0.035289</td>\n",
       "      <td>-0.303618</td>\n",
       "      <td>-0.818045</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.560083</td>\n",
       "      <td>1.078656</td>\n",
       "      <td>-0.317126</td>\n",
       "      <td>0.316186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Trevor Roberts School</td>\n",
       "      <td>F</td>\n",
       "      <td>11.838889</td>\n",
       "      <td>-0.587075</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>0.041414</td>\n",
       "      <td>0.528114</td>\n",
       "      <td>-0.142475</td>\n",
       "      <td>0.804932</td>\n",
       "      <td>0.698279</td>\n",
       "      <td>0.486952</td>\n",
       "      <td>-0.435025</td>\n",
       "      <td>-0.862134</td>\n",
       "      <td>0.812849</td>\n",
       "      <td>0.685928</td>\n",
       "      <td>0.486859</td>\n",
       "      <td>-0.426516</td>\n",
       "      <td>-0.851632</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1.152471</td>\n",
       "      <td>0.028908</td>\n",
       "      <td>0.242714</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>1.014859</td>\n",
       "      <td>0.713503</td>\n",
       "      <td>-0.007000</td>\n",
       "      <td>-0.640517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Trevor Roberts School</td>\n",
       "      <td>M</td>\n",
       "      <td>7.611111</td>\n",
       "      <td>1.040539</td>\n",
       "      <td>0.043889</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.052972</td>\n",
       "      <td>0.770192</td>\n",
       "      <td>0.132597</td>\n",
       "      <td>0.880334</td>\n",
       "      <td>0.755154</td>\n",
       "      <td>0.530449</td>\n",
       "      <td>-0.589862</td>\n",
       "      <td>-0.083494</td>\n",
       "      <td>0.846292</td>\n",
       "      <td>0.747178</td>\n",
       "      <td>0.556262</td>\n",
       "      <td>-0.601976</td>\n",
       "      <td>-0.080824</td>\n",
       "      <td>66</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.093324</td>\n",
       "      <td>-0.380691</td>\n",
       "      <td>0.525759</td>\n",
       "      <td>-0.140001</td>\n",
       "      <td>-0.205424</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>1.009100</td>\n",
       "      <td>2.680493</td>\n",
       "      <td>-0.377855</td>\n",
       "      <td>0.987913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Trevor Roberts School</td>\n",
       "      <td>M</td>\n",
       "      <td>6.747222</td>\n",
       "      <td>0.226732</td>\n",
       "      <td>0.013740</td>\n",
       "      <td>-0.022676</td>\n",
       "      <td>0.054293</td>\n",
       "      <td>0.582383</td>\n",
       "      <td>0.028154</td>\n",
       "      <td>0.651551</td>\n",
       "      <td>0.764537</td>\n",
       "      <td>0.577141</td>\n",
       "      <td>0.588800</td>\n",
       "      <td>0.396509</td>\n",
       "      <td>0.652178</td>\n",
       "      <td>0.783163</td>\n",
       "      <td>0.582775</td>\n",
       "      <td>0.589636</td>\n",
       "      <td>0.395179</td>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>0.458539</td>\n",
       "      <td>-1.489266</td>\n",
       "      <td>-0.041334</td>\n",
       "      <td>-0.248403</td>\n",
       "      <td>1.083356</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>1.776796</td>\n",
       "      <td>2.286356</td>\n",
       "      <td>-0.003408</td>\n",
       "      <td>-0.071924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>Trevor Roberts School</td>\n",
       "      <td>M</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>0.226732</td>\n",
       "      <td>-0.014891</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>-0.040881</td>\n",
       "      <td>0.448529</td>\n",
       "      <td>-0.036160</td>\n",
       "      <td>0.553742</td>\n",
       "      <td>0.489282</td>\n",
       "      <td>0.530107</td>\n",
       "      <td>-0.303803</td>\n",
       "      <td>-1.629661</td>\n",
       "      <td>0.553467</td>\n",
       "      <td>0.487266</td>\n",
       "      <td>0.528799</td>\n",
       "      <td>-0.305209</td>\n",
       "      <td>-1.630474</td>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.133400</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>-0.679340</td>\n",
       "      <td>-0.246747</td>\n",
       "      <td>0.085989</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.167615</td>\n",
       "      <td>1.790722</td>\n",
       "      <td>0.068897</td>\n",
       "      <td>-1.590435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>Broadfields</td>\n",
       "      <td>M</td>\n",
       "      <td>10.486111</td>\n",
       "      <td>-2.214688</td>\n",
       "      <td>0.098073</td>\n",
       "      <td>0.071605</td>\n",
       "      <td>0.120545</td>\n",
       "      <td>0.422117</td>\n",
       "      <td>0.117357</td>\n",
       "      <td>0.433004</td>\n",
       "      <td>0.519166</td>\n",
       "      <td>0.491737</td>\n",
       "      <td>0.173996</td>\n",
       "      <td>-0.269121</td>\n",
       "      <td>0.436899</td>\n",
       "      <td>0.517092</td>\n",
       "      <td>0.471755</td>\n",
       "      <td>0.175653</td>\n",
       "      <td>-0.262585</td>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>0.329597</td>\n",
       "      <td>0.200856</td>\n",
       "      <td>-0.572747</td>\n",
       "      <td>0.212403</td>\n",
       "      <td>0.187235</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.629227</td>\n",
       "      <td>0.402836</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>1.374665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Merton Court</td>\n",
       "      <td>M</td>\n",
       "      <td>10.372222</td>\n",
       "      <td>-0.587075</td>\n",
       "      <td>-0.017052</td>\n",
       "      <td>-0.065302</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.610913</td>\n",
       "      <td>-0.218845</td>\n",
       "      <td>0.445750</td>\n",
       "      <td>0.349609</td>\n",
       "      <td>0.394229</td>\n",
       "      <td>-0.074491</td>\n",
       "      <td>-0.851411</td>\n",
       "      <td>0.453946</td>\n",
       "      <td>0.367773</td>\n",
       "      <td>0.398445</td>\n",
       "      <td>-0.070527</td>\n",
       "      <td>-0.840291</td>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0.680336</td>\n",
       "      <td>-0.707812</td>\n",
       "      <td>-0.136637</td>\n",
       "      <td>0.689489</td>\n",
       "      <td>-0.980713</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.094336</td>\n",
       "      <td>0.913792</td>\n",
       "      <td>-0.342356</td>\n",
       "      <td>-1.236251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>Orley Farm</td>\n",
       "      <td>M</td>\n",
       "      <td>8.608333</td>\n",
       "      <td>0.498001</td>\n",
       "      <td>0.057756</td>\n",
       "      <td>0.049645</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.718295</td>\n",
       "      <td>0.107204</td>\n",
       "      <td>1.381509</td>\n",
       "      <td>0.868366</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.382585</td>\n",
       "      <td>-0.281852</td>\n",
       "      <td>1.387507</td>\n",
       "      <td>0.884099</td>\n",
       "      <td>0.678044</td>\n",
       "      <td>0.386831</td>\n",
       "      <td>-0.277990</td>\n",
       "      <td>64</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.330512</td>\n",
       "      <td>0.909617</td>\n",
       "      <td>0.208257</td>\n",
       "      <td>-0.148340</td>\n",
       "      <td>-0.622866</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.964536</td>\n",
       "      <td>3.303898</td>\n",
       "      <td>-0.710446</td>\n",
       "      <td>0.139772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>Newland House</td>\n",
       "      <td>F</td>\n",
       "      <td>11.236111</td>\n",
       "      <td>1.040539</td>\n",
       "      <td>0.044004</td>\n",
       "      <td>0.045351</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.893768</td>\n",
       "      <td>0.043038</td>\n",
       "      <td>1.296684</td>\n",
       "      <td>0.839617</td>\n",
       "      <td>0.514458</td>\n",
       "      <td>0.758670</td>\n",
       "      <td>-0.065990</td>\n",
       "      <td>1.165809</td>\n",
       "      <td>0.808938</td>\n",
       "      <td>0.521772</td>\n",
       "      <td>0.873589</td>\n",
       "      <td>-0.060433</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>0.458539</td>\n",
       "      <td>-0.562425</td>\n",
       "      <td>-0.814565</td>\n",
       "      <td>0.551108</td>\n",
       "      <td>-0.565334</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.221067</td>\n",
       "      <td>1.221168</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>-1.571437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>210</td>\n",
       "      <td>0</td>\n",
       "      <td>Orley Farm</td>\n",
       "      <td>M</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>0.633636</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>-0.007576</td>\n",
       "      <td>0.630908</td>\n",
       "      <td>0.307179</td>\n",
       "      <td>0.682308</td>\n",
       "      <td>0.277862</td>\n",
       "      <td>0.499937</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>-1.319046</td>\n",
       "      <td>0.717552</td>\n",
       "      <td>0.251539</td>\n",
       "      <td>0.506072</td>\n",
       "      <td>0.021058</td>\n",
       "      <td>-1.268473</td>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.126972</td>\n",
       "      <td>0.022219</td>\n",
       "      <td>-0.804177</td>\n",
       "      <td>0.712123</td>\n",
       "      <td>-0.258350</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>0.831928</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>-0.388742</td>\n",
       "      <td>2.137394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  Session                 School Gender  Age_Frac_Imp  SES_inv_z  \\\n",
       "0     1        0  Trevor Roberts School      M     12.444444   0.226732   \n",
       "1     4        0  Trevor Roberts School      F     11.838889  -0.587075   \n",
       "2     5        0  Trevor Roberts School      M      7.611111   1.040539   \n",
       "3     8        0  Trevor Roberts School      M      6.747222   0.226732   \n",
       "4    15        0  Trevor Roberts School      M     10.600000   0.226732   \n",
       "..  ...      ...                    ...    ...           ...        ...   \n",
       "64  193        0            Broadfields      M     10.486111  -2.214688   \n",
       "65  195        0           Merton Court      M     10.372222  -0.587075   \n",
       "66  196        0             Orley Farm      M      8.608333   0.498001   \n",
       "67  202        0          Newland House      F     11.236111   1.040539   \n",
       "68  210        0             Orley Farm      M      8.666667   0.633636   \n",
       "\n",
       "     Avg_Pts  Avg_Pts_lo  Avg_Pts_hi      w_P6    w_diff     it_P6     lr_P6  \\\n",
       "0   0.013173   -0.002222    0.029551  0.425788  0.121567  0.619787  0.437227   \n",
       "1   0.024752    0.004831    0.041414  0.528114 -0.142475  0.804932  0.698279   \n",
       "2   0.043889    0.037037    0.052972  0.770192  0.132597  0.880334  0.755154   \n",
       "3   0.013740   -0.022676    0.054293  0.582383  0.028154  0.651551  0.764537   \n",
       "4  -0.014891    0.016414   -0.040881  0.448529 -0.036160  0.553742  0.489282   \n",
       "..       ...         ...         ...       ...       ...       ...       ...   \n",
       "64  0.098073    0.071605    0.120545  0.422117  0.117357  0.433004  0.519166   \n",
       "65 -0.017052   -0.065302    0.045455  0.610913 -0.218845  0.445750  0.349609   \n",
       "66  0.057756    0.049645    0.064815  0.718295  0.107204  1.381509  0.868366   \n",
       "67  0.044004    0.045351    0.042735  0.893768  0.043038  1.296684  0.839617   \n",
       "68  0.007092    0.020000   -0.007576  0.630908  0.307179  0.682308  0.277862   \n",
       "\n",
       "       eg_P6     st_P6  repst_P6        it        lr        eg        st  \\\n",
       "0   0.419932 -0.177439 -0.709067  0.625122  0.442486  0.420558 -0.177359   \n",
       "1   0.486952 -0.435025 -0.862134  0.812849  0.685928  0.486859 -0.426516   \n",
       "2   0.530449 -0.589862 -0.083494  0.846292  0.747178  0.556262 -0.601976   \n",
       "3   0.577141  0.588800  0.396509  0.652178  0.783163  0.582775  0.589636   \n",
       "4   0.530107 -0.303803 -1.629661  0.553467  0.487266  0.528799 -0.305209   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "64  0.491737  0.173996 -0.269121  0.436899  0.517092  0.471755  0.175653   \n",
       "65  0.394229 -0.074491 -0.851411  0.453946  0.367773  0.398445 -0.070527   \n",
       "66  0.658000  0.382585 -0.281852  1.387507  0.884099  0.678044  0.386831   \n",
       "67  0.514458  0.758670 -0.065990  1.165809  0.808938  0.521772  0.873589   \n",
       "68  0.499937  0.021814 -1.319046  0.717552  0.251539  0.506072  0.021058   \n",
       "\n",
       "       repst  T_Vocab  T_Matrix  Corsi_WM_Span  CogFlex_t      SSRT  \\\n",
       "0  -0.704026       62        66              7   0.524022 -0.798678   \n",
       "1  -0.851632       55        50              5   1.152471  0.028908   \n",
       "2  -0.080824       66        55              4  -1.093324 -0.380691   \n",
       "3   0.395179       64        61              4   0.458539 -1.489266   \n",
       "4  -1.630474       55        62              6  -0.133400  0.016327   \n",
       "..       ...      ...       ...            ...        ...       ...   \n",
       "64 -0.262585       41        56              6   0.329597  0.200856   \n",
       "65 -0.840291       58        64              6   0.680336 -0.707812   \n",
       "66 -0.277990       64        52              5  -0.330512  0.909617   \n",
       "67 -0.060433       63        54              7   0.458539 -0.562425   \n",
       "68 -1.268473       80        65              5  -0.126972  0.022219   \n",
       "\n",
       "    FlankerSwitch_t  FlankerInhib_t  Stroop_t  dprimeONEBACK_t0  \\\n",
       "0          0.035289       -0.303618 -0.818045          0.958333   \n",
       "1          0.242714        0.563637 -0.013837          0.958333   \n",
       "2          0.525759       -0.140001 -0.205424          0.607143   \n",
       "3         -0.041334       -0.248403  1.083356          0.630952   \n",
       "4         -0.679340       -0.246747  0.085989          0.833333   \n",
       "..              ...             ...       ...               ...   \n",
       "64        -0.572747        0.212403  0.187235         -0.083333   \n",
       "65        -0.136637        0.689489 -0.980713          0.958333   \n",
       "66         0.208257       -0.148340 -0.622866          0.630952   \n",
       "67        -0.814565        0.551108 -0.565334          0.880952   \n",
       "68        -0.804177        0.712123 -0.258350          0.886905   \n",
       "\n",
       "    dprimeTWOBACK_t0  AY_Inv_eff_score  BX_Inv_eff_score  CF_Mix_IES_Diff  \\\n",
       "0           0.851190          0.560083          1.078656        -0.317126   \n",
       "1           0.880952          1.014859          0.713503        -0.007000   \n",
       "2          -0.023810          1.009100          2.680493        -0.377855   \n",
       "3          -0.166667          1.776796          2.286356        -0.003408   \n",
       "4           0.833333          2.167615          1.790722         0.068897   \n",
       "..               ...               ...               ...              ...   \n",
       "64          0.023810          0.629227          0.402836         0.016885   \n",
       "65          0.714286          1.094336          0.913792        -0.342356   \n",
       "66          0.797619          0.964536          3.303898        -0.710446   \n",
       "67          0.464286          1.221067          1.221168         0.005142   \n",
       "68         -0.285714          0.831928          0.280486        -0.388742   \n",
       "\n",
       "    SSRT_SSD_z  \n",
       "0     0.316186  \n",
       "1    -0.640517  \n",
       "2     0.987913  \n",
       "3    -0.071924  \n",
       "4    -1.590435  \n",
       "..         ...  \n",
       "64    1.374665  \n",
       "65   -1.236251  \n",
       "66    0.139772  \n",
       "67   -1.571437  \n",
       "68    2.137394  \n",
       "\n",
       "[69 rows x 35 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#work_p = \"C:/Users/claire.smid/Documents/Main_STUDY/Model-based_learning_mainstudy/\"\n",
    "\n",
    "work_p = \"C:/Users/claire.smid/Documents/DCP/Writing/Thesis/Chapter2/\"\n",
    "\n",
    "# Including all decision making, EFs and mental health:\n",
    "#dataset = pd.read_csv(work_p+\"All_DMs_EFs_MHs_Nov21.csv\", sep=',') \n",
    "\n",
    "# Including all decision making and EFs\n",
    "#dataset = pd.read_csv(work_p+\"All_DMs_EFs_Nov21.csv\", sep=',') \n",
    "\n",
    "# Including EFs and MB only\n",
    "#dataset = pd.read_csv(work_p+\"MB_EFs_Only_Nov21.csv\", sep=',') \n",
    "#dataset = pd.read_csv(work_p+\"MB_EF_Detail_Imputed_Dec21.csv\", sep=',') \n",
    "#dataset = pd.read_csv(work_p+\"MB_EF_Detail_Imputed_REDUCED_Dec21.csv\", sep=',') \n",
    "#dataset = pd.read_csv(work_p+\"MBMF_EF_Detail_Imp_6Jun2022.csv\", sep=',') \n",
    "#dataset = pd.read_csv(work_p+\"MBMF_EF_Detail_Imp_9Jun2022.csv\", sep=',') \n",
    "dataset = pd.read_csv(work_p+\"MBMF_EF_Detail_Imp_14Jun2022.csv\", sep=',') \n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2a199a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\claire.smid\\\\Documents\\\\DCP\\\\Writing\\\\Thesis\\\\Chapter2'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"C:/Users/claire.smid/Documents/DCP/Writing/Thesis/Chapter2/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d89b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding\n",
    "dataset.Gender.replace(to_replace=['M','F'],value=[1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9fd078e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from column 8 onwards no more model parameters, or maybe just include all?\n",
    "# now including only the EFs for the first approach, and splitting factors for the later approach\n",
    "#X = dataset.iloc[:, np.r_[4:5,10:len(dataset.columns)]]\n",
    "\n",
    "# # 6 jun dataset\n",
    "# X = dataset.iloc[:, np.r_[14:34]]\n",
    "# X_cols = X\n",
    "# y = dataset.iloc[:,8]\n",
    "\n",
    "# 7 jun dataset\n",
    "X = dataset.iloc[:, np.r_[21:35]]\n",
    "X_cols = X\n",
    "y = dataset.iloc[:,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ca82a241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y.reshape(len(y),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d4c64875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T_Vocab</th>\n",
       "      <th>T_Matrix</th>\n",
       "      <th>Corsi_WM_Span</th>\n",
       "      <th>CogFlex_t</th>\n",
       "      <th>SSRT</th>\n",
       "      <th>FlankerSwitch_t</th>\n",
       "      <th>FlankerInhib_t</th>\n",
       "      <th>Stroop_t</th>\n",
       "      <th>dprimeONEBACK_t0</th>\n",
       "      <th>dprimeTWOBACK_t0</th>\n",
       "      <th>AY_Inv_eff_score</th>\n",
       "      <th>BX_Inv_eff_score</th>\n",
       "      <th>CF_Mix_IES_Diff</th>\n",
       "      <th>SSRT_SSD_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>0.524022</td>\n",
       "      <td>-0.798678</td>\n",
       "      <td>0.035289</td>\n",
       "      <td>-0.303618</td>\n",
       "      <td>-0.818045</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.560083</td>\n",
       "      <td>1.078656</td>\n",
       "      <td>-0.317126</td>\n",
       "      <td>0.316186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1.152471</td>\n",
       "      <td>0.028908</td>\n",
       "      <td>0.242714</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>-0.013837</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>1.014859</td>\n",
       "      <td>0.713503</td>\n",
       "      <td>-0.007000</td>\n",
       "      <td>-0.640517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>-1.093324</td>\n",
       "      <td>-0.380691</td>\n",
       "      <td>0.525759</td>\n",
       "      <td>-0.140001</td>\n",
       "      <td>-0.205424</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>-0.023810</td>\n",
       "      <td>1.009100</td>\n",
       "      <td>2.680493</td>\n",
       "      <td>-0.377855</td>\n",
       "      <td>0.987913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>0.458539</td>\n",
       "      <td>-1.489266</td>\n",
       "      <td>-0.041334</td>\n",
       "      <td>-0.248403</td>\n",
       "      <td>1.083356</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>1.776796</td>\n",
       "      <td>2.286356</td>\n",
       "      <td>-0.003408</td>\n",
       "      <td>-0.071924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55</td>\n",
       "      <td>62</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.133400</td>\n",
       "      <td>0.016327</td>\n",
       "      <td>-0.679340</td>\n",
       "      <td>-0.246747</td>\n",
       "      <td>0.085989</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>2.167615</td>\n",
       "      <td>1.790722</td>\n",
       "      <td>0.068897</td>\n",
       "      <td>-1.590435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>41</td>\n",
       "      <td>56</td>\n",
       "      <td>6</td>\n",
       "      <td>0.329597</td>\n",
       "      <td>0.200856</td>\n",
       "      <td>-0.572747</td>\n",
       "      <td>0.212403</td>\n",
       "      <td>0.187235</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.629227</td>\n",
       "      <td>0.402836</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>1.374665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>58</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0.680336</td>\n",
       "      <td>-0.707812</td>\n",
       "      <td>-0.136637</td>\n",
       "      <td>0.689489</td>\n",
       "      <td>-0.980713</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.094336</td>\n",
       "      <td>0.913792</td>\n",
       "      <td>-0.342356</td>\n",
       "      <td>-1.236251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>64</td>\n",
       "      <td>52</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.330512</td>\n",
       "      <td>0.909617</td>\n",
       "      <td>0.208257</td>\n",
       "      <td>-0.148340</td>\n",
       "      <td>-0.622866</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.964536</td>\n",
       "      <td>3.303898</td>\n",
       "      <td>-0.710446</td>\n",
       "      <td>0.139772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>7</td>\n",
       "      <td>0.458539</td>\n",
       "      <td>-0.562425</td>\n",
       "      <td>-0.814565</td>\n",
       "      <td>0.551108</td>\n",
       "      <td>-0.565334</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>1.221067</td>\n",
       "      <td>1.221168</td>\n",
       "      <td>0.005142</td>\n",
       "      <td>-1.571437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>80</td>\n",
       "      <td>65</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.126972</td>\n",
       "      <td>0.022219</td>\n",
       "      <td>-0.804177</td>\n",
       "      <td>0.712123</td>\n",
       "      <td>-0.258350</td>\n",
       "      <td>0.886905</td>\n",
       "      <td>-0.285714</td>\n",
       "      <td>0.831928</td>\n",
       "      <td>0.280486</td>\n",
       "      <td>-0.388742</td>\n",
       "      <td>2.137394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    T_Vocab  T_Matrix  Corsi_WM_Span  CogFlex_t      SSRT  FlankerSwitch_t  \\\n",
       "0        62        66              7   0.524022 -0.798678         0.035289   \n",
       "1        55        50              5   1.152471  0.028908         0.242714   \n",
       "2        66        55              4  -1.093324 -0.380691         0.525759   \n",
       "3        64        61              4   0.458539 -1.489266        -0.041334   \n",
       "4        55        62              6  -0.133400  0.016327        -0.679340   \n",
       "..      ...       ...            ...        ...       ...              ...   \n",
       "64       41        56              6   0.329597  0.200856        -0.572747   \n",
       "65       58        64              6   0.680336 -0.707812        -0.136637   \n",
       "66       64        52              5  -0.330512  0.909617         0.208257   \n",
       "67       63        54              7   0.458539 -0.562425        -0.814565   \n",
       "68       80        65              5  -0.126972  0.022219        -0.804177   \n",
       "\n",
       "    FlankerInhib_t  Stroop_t  dprimeONEBACK_t0  dprimeTWOBACK_t0  \\\n",
       "0        -0.303618 -0.818045          0.958333          0.851190   \n",
       "1         0.563637 -0.013837          0.958333          0.880952   \n",
       "2        -0.140001 -0.205424          0.607143         -0.023810   \n",
       "3        -0.248403  1.083356          0.630952         -0.166667   \n",
       "4        -0.246747  0.085989          0.833333          0.833333   \n",
       "..             ...       ...               ...               ...   \n",
       "64        0.212403  0.187235         -0.083333          0.023810   \n",
       "65        0.689489 -0.980713          0.958333          0.714286   \n",
       "66       -0.148340 -0.622866          0.630952          0.797619   \n",
       "67        0.551108 -0.565334          0.880952          0.464286   \n",
       "68        0.712123 -0.258350          0.886905         -0.285714   \n",
       "\n",
       "    AY_Inv_eff_score  BX_Inv_eff_score  CF_Mix_IES_Diff  SSRT_SSD_z  \n",
       "0           0.560083          1.078656        -0.317126    0.316186  \n",
       "1           1.014859          0.713503        -0.007000   -0.640517  \n",
       "2           1.009100          2.680493        -0.377855    0.987913  \n",
       "3           1.776796          2.286356        -0.003408   -0.071924  \n",
       "4           2.167615          1.790722         0.068897   -1.590435  \n",
       "..               ...               ...              ...         ...  \n",
       "64          0.629227          0.402836         0.016885    1.374665  \n",
       "65          1.094336          0.913792        -0.342356   -1.236251  \n",
       "66          0.964536          3.303898        -0.710446    0.139772  \n",
       "67          1.221067          1.221168         0.005142   -1.571437  \n",
       "68          0.831928          0.280486        -0.388742    2.137394  \n",
       "\n",
       "[69 rows x 14 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8b35a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X['SSRT_SSD_z'] = X['SSRT_SSD_z']*-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5e07e222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.121567\n",
       "1    -0.142475\n",
       "2     0.132597\n",
       "3     0.028154\n",
       "4    -0.036160\n",
       "        ...   \n",
       "64    0.117357\n",
       "65   -0.218845\n",
       "66    0.107204\n",
       "67    0.043038\n",
       "68    0.307179\n",
       "Name: w_diff, Length: 69, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b44aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "#y = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f5da70b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.92986510e-01,  1.04805356e+00,  1.86614836e+00,\n",
       "         8.23574689e-01, -7.81869423e-01,  5.14227132e-02,\n",
       "        -7.91541408e-01, -1.14774038e+00,  6.10112522e-01,\n",
       "         1.22443140e+00, -1.02573375e+00, -5.17512920e-01,\n",
       "        -5.86473127e-01,  3.26870645e-01],\n",
       "       [-2.27315726e-01, -4.74382139e-01, -4.33213013e-01,\n",
       "         2.10259875e+00,  1.12205581e-01,  4.10626096e-01,\n",
       "         8.80136899e-01,  8.30817957e-02,  6.10112522e-01,\n",
       "         1.32190020e+00, -5.92275389e-01, -7.27249849e-01,\n",
       "         2.77194477e-01, -6.33199335e-01],\n",
       "       [ 7.47444930e-01,  1.37901785e-03, -1.58289370e+00,\n",
       "        -2.46805900e+00, -3.30301201e-01,  9.00782032e-01,\n",
       "        -4.76162864e-01, -2.10138461e-01, -1.01752061e+00,\n",
       "        -1.64114498e+00, -5.97764683e-01,  4.02551810e-01,\n",
       "        -7.55595816e-01,  1.00096233e+00],\n",
       "       [ 5.70215720e-01,  5.72292406e-01, -1.58289370e+00,\n",
       "         6.90302678e-01, -1.52793872e+00, -8.12659299e-02,\n",
       "        -6.85112426e-01,  1.76230932e+00, -9.07172466e-01,\n",
       "        -2.10899419e+00,  1.33946008e-01,  1.76166943e-01,\n",
       "         2.87197669e-01, -6.26045524e-02],\n",
       "       [-2.27315726e-01,  6.67444638e-01,  7.16467676e-01,\n",
       "        -5.14415588e-01,  9.86132474e-02, -1.18611812e+00,\n",
       "        -6.81920536e-01,  2.35861922e-01,  3.07854159e-02,\n",
       "         1.16595026e+00,  5.06444636e-01, -1.08515503e-01,\n",
       "         4.88557926e-01, -1.58646031e+00],\n",
       "       [ 3.92986510e-01,  1.23835803e+00, -4.33213013e-01,\n",
       "        -9.15579213e-01,  1.04403690e+00,  1.35509731e+00,\n",
       "         1.28213386e+00, -6.97989258e-01,  6.10112522e-01,\n",
       "        -9.00383763e-01,  1.34071637e+00, -7.49099014e-01,\n",
       "        -1.42063883e-01,  1.14122788e+00],\n",
       "       [ 1.27142694e-01,  9.52901332e-01,  7.16467676e-01,\n",
       "         1.14170474e+00, -2.71400998e-01,  6.07786805e-02,\n",
       "        -2.04069223e-01,  1.55229533e+00,  2.79068375e-01,\n",
       "         7.76076035e-01,  1.06956340e-01, -8.06939196e-01,\n",
       "        -4.24329085e-01, -4.52079750e-01],\n",
       "       [-5.81774147e-01, -1.23559999e+00, -4.33213013e-01,\n",
       "         1.97249253e-01, -6.44435633e-01,  1.41750103e+00,\n",
       "        -3.87761210e-01, -6.84728289e-01,  4.44590564e-01,\n",
       "         1.04898800e+00, -4.18318950e-01, -3.44204512e-01,\n",
       "        -7.12634530e-01, -8.23851530e-01],\n",
       "       [-2.79713928e+00, -6.64686602e-01,  7.16467676e-01,\n",
       "        -1.60485226e+00, -2.71400998e-01,  6.02474730e-01,\n",
       "        -6.66439056e-01,  6.26312493e-01,  4.17003703e-01,\n",
       "        -4.26601990e-02,  3.97492102e-01,  2.16812332e+00,\n",
       "        -5.18624405e-01,  3.26870645e-01],\n",
       "       [ 2.15757299e-01,  1.04805356e+00,  7.16467676e-01,\n",
       "         1.48228565e-01,  7.67659115e-01,  7.71739239e-02,\n",
       "         3.32464463e-01, -4.45732243e-01,  6.10112522e-01,\n",
       "         2.30251868e-01, -2.83814992e-01, -3.64332358e-01,\n",
       "        -8.91067935e-02, -1.16089737e+00],\n",
       "       [ 5.70215720e-01,  9.65312493e-02,  7.16467676e-01,\n",
       "         4.13826866e-01,  5.72835264e-01,  2.43100871e-01,\n",
       "         3.26169985e-01, -3.16391196e-01,  6.10112522e-01,\n",
       "         5.42151331e-01, -9.93398258e-01, -3.40285365e-01,\n",
       "         8.57048086e-01,  6.45532170e-01],\n",
       "       [-2.27315726e-01, -1.88925445e-01, -1.58289370e+00,\n",
       "        -2.04850687e-01, -6.83702453e-01,  4.87027415e-02,\n",
       "         2.28013445e+00,  2.01322348e+00,  4.44590564e-01,\n",
       "         6.59113585e-01, -1.68078548e-01, -4.53976757e-01,\n",
       "        -5.87255600e-01,  1.38907573e+00],\n",
       "       [ 5.70215720e-01, -7.59838834e-01, -4.33213013e-01,\n",
       "         5.22825355e-02,  3.99155058e-01, -3.45004591e-01,\n",
       "        -4.45587633e-01,  2.00733726e+00,  2.79068375e-01,\n",
       "        -7.05446488e-01,  2.37033050e+00,  1.14339715e+00,\n",
       "        -8.40655192e-01,  1.00096233e+00],\n",
       "       [ 1.98804940e+00,  3.81987944e-01, -1.58289370e+00,\n",
       "        -5.58532506e-01,  1.99800640e-01, -1.11722079e+00,\n",
       "        -1.19371013e+00, -3.13170185e-01, -9.07172466e-01,\n",
       "        -1.29025806e+00, -3.04020185e-01,  1.16739680e+00,\n",
       "         5.99585127e-01,  2.06180562e+00],\n",
       "       [-6.70388752e-01,  2.86835712e-01, -4.33213013e-01,\n",
       "        -1.18055849e+00,  1.14220393e+00, -1.91753361e+00,\n",
       "         1.35166700e-01, -6.66407779e-01,  6.10112522e-01,\n",
       "         2.30251868e-01, -7.65454052e-01, -7.29501303e-01,\n",
       "        -6.94736455e-01,  1.07041420e+00],\n",
       "       [ 1.19051796e+00,  1.42866249e+00, -4.33213013e-01,\n",
       "        -8.15855107e-01,  1.29927120e+00, -2.27936920e+00,\n",
       "         1.86206158e+00, -8.78914059e-01,  6.10112522e-01,\n",
       "         7.43021528e-02, -3.27830983e-01, -7.58560638e-01,\n",
       "        -1.68182442e+00,  1.95558511e+00],\n",
       "       [ 1.27142694e-01, -8.54991065e-01, -4.33213013e-01,\n",
       "        -8.04254264e-01,  5.13935061e-01,  5.02133874e-02,\n",
       "         1.16635035e+00,  6.70897805e-01,  6.10112522e-01,\n",
       "        -1.98609914e-01, -4.30038491e-01, -6.33308415e-01,\n",
       "         3.89775655e-01, -8.06148111e-01],\n",
       "       [ 3.85280892e-02, -9.50143297e-01, -1.58289370e+00,\n",
       "         2.22243561e+00, -1.82243968e+00, -1.33523942e+00,\n",
       "         1.08028443e+00,  8.94764845e-01, -3.00258731e-01,\n",
       "        -5.88484267e-01,  8.58837273e-02, -8.48383407e-01,\n",
       "        -4.92155027e-01,  2.56056973e-01],\n",
       "       [-3.15159770e+00,  2.09472811e+00, -1.58289370e+00,\n",
       "        -1.57012585e+00, -1.66537253e+00, -8.44251396e-03,\n",
       "        -1.29273139e-01,  2.47607532e-01, -7.41650509e-01,\n",
       "         1.13289451e-01,  1.26127410e+00,  2.38582177e+00,\n",
       "        -1.80792130e+00,  4.33091154e-01],\n",
       "       [-3.06298309e+00, -2.18712231e+00, -1.58289370e+00,\n",
       "        -2.71001949e-01,  3.37234451e-01, -2.64111585e-01,\n",
       "         2.42867866e-01, -1.31789533e+00,  1.13546418e-01,\n",
       "        -4.71522014e-01,  4.64591527e+00,  6.97061056e-02,\n",
       "        -4.34957190e-01, -2.04231897e-01],\n",
       "       [-6.70388752e-01, -9.50143297e-01,  7.16467676e-01,\n",
       "        -1.79479660e+00,  4.35401453e-01, -1.85003721e+00,\n",
       "        -2.50032791e-01, -1.94647481e-01,  4.17003703e-01,\n",
       "         7.76076035e-01, -1.45836074e-01, -9.36723228e-01,\n",
       "        -3.23147956e-01, -5.93707095e-01],\n",
       "       [-4.04544936e-01, -1.88925445e-01, -4.33213013e-01,\n",
       "         4.13826866e-01,  2.97967642e-01, -3.28208037e-01,\n",
       "         4.21151911e-01, -6.88852220e-01,  6.10112522e-01,\n",
       "        -1.29025806e+00,  2.14525991e-01, -8.52106441e-01,\n",
       "         3.13752057e+00, -6.46817349e-01],\n",
       "       [-4.04544936e-01,  1.37901785e-03,  1.86614836e+00,\n",
       "         1.57775627e+00,  7.69169257e-01,  6.02852870e-01,\n",
       "        -1.06509156e+00,  1.09710117e+00, -4.21761323e+00,\n",
       "        -9.00383763e-01, -2.63666086e-01, -4.62671843e-01,\n",
       "        -3.27721339e-01, -1.68825061e-01],\n",
       "       [ 3.92986510e-01,  2.86835712e-01, -4.33213013e-01,\n",
       "         8.57803268e-01, -8.56389293e-02, -9.14230182e-01,\n",
       "        -1.06652535e+00,  1.03868710e+00,  4.44590564e-01,\n",
       "         3.08226660e-01, -5.02210712e-01, -8.72617070e-01,\n",
       "        -4.12117045e-01, -1.50134772e+00],\n",
       "       [-7.59003357e-01,  7.62596869e-01, -1.58289370e+00,\n",
       "         6.48942061e-01, -1.36785115e+00,  1.83704811e+00,\n",
       "        -5.09551164e-01, -6.89590231e-01,  2.51481745e-01,\n",
       "        -1.36823293e+00,  1.86195389e+00,  1.25549016e+00,\n",
       "         1.37747443e-01,  1.44354779e+00],\n",
       "       [-3.15930331e-01,  9.52901332e-01,  1.86614836e+00,\n",
       "         2.64366514e-01,  1.73120608e+00, -1.40230091e+00,\n",
       "         4.66789147e-01, -8.80205908e-02,  4.44590564e-01,\n",
       "         2.69239362e-01, -1.00402127e+00, -8.61171220e-01,\n",
       "        -1.03043011e+00,  3.26870645e-01],\n",
       "       [ 1.36774717e+00, -1.52105669e+00, -1.58289370e+00,\n",
       "         1.57775627e+00,  1.51523858e+00,  1.49927019e+00,\n",
       "        -2.04069223e-01,  5.57193119e-01,  6.10112522e-01,\n",
       "         3.86201616e-01, -4.37162005e-02,  2.81479019e+00,\n",
       "        -1.05949960e+00,  7.87159515e-01],\n",
       "       [-5.00865159e-02,  1.33351026e+00, -4.33213013e-01,\n",
       "         1.43871923e+00, -9.47003877e-02,  1.49676610e+00,\n",
       "         1.08028443e+00, -1.33595677e+00, -6.31302645e-01,\n",
       "        -2.76584804e-01, -2.42636616e-01, -8.56623166e-01,\n",
       "         7.45900764e-01, -2.39638733e-01],\n",
       "       [ 5.70215720e-01,  1.52381472e+00,  7.16467676e-01,\n",
       "        -1.33476156e+00, -3.69567989e-01,  1.41750103e+00,\n",
       "        -6.66439056e-01, -5.37015415e-01, -7.95624475e-02,\n",
       "        -8.16475623e-02, -9.40083904e-01, -8.51025996e-01,\n",
       "        -3.54505772e-01,  7.87159515e-01],\n",
       "       [-6.70388752e-01,  1.37901785e-03,  7.16467676e-01,\n",
       "         2.28097089e-01, -1.58683884e+00, -1.24048628e+00,\n",
       "         1.41471628e+00,  9.51300161e-02,  6.10112522e-01,\n",
       "         5.03164066e-01, -7.86237234e-01, -6.39407879e-01,\n",
       "        -2.29827344e-01, -6.29113931e-01],\n",
       "       [ 1.81082019e+00,  9.65312493e-02, -4.33213013e-01,\n",
       "        -1.14528230e+00, -6.24802250e-01,  1.54981697e+00,\n",
       "        -2.65146959e+00, -2.72501776e-01,  4.17003703e-01,\n",
       "        -4.32534520e-01, -8.13299358e-01, -2.01725264e-01,\n",
       "         9.39571180e-01,  2.91463809e-01],\n",
       "       [-1.02484717e+00,  1.37901785e-03, -1.58289370e+00,\n",
       "        -1.21635326e+00, -1.61667775e-02, -1.22986391e+00,\n",
       "         1.56691073e-01,  1.11399403e+00,  8.59595099e-02,\n",
       "         9.32025586e-01, -8.01264840e-01, -1.80734244e-01,\n",
       "         3.04501767e-01,  2.20650137e-01],\n",
       "       [ 1.27142694e-01,  3.81987944e-01,  7.16467676e-01,\n",
       "        -1.60508292e-01,  3.96134654e-01, -4.76825581e-01,\n",
       "        -1.79002405e+00,  2.14148829e+00,  6.10112522e-01,\n",
       "        -4.26601990e-02,  1.27326583e+00,  2.81479019e+00,\n",
       "         3.13752057e+00, -1.33112255e+00],\n",
       "       [-1.11346178e+00,  9.65312493e-02,  7.16467676e-01,\n",
       "         8.66346116e-02, -8.80036447e-01,  1.04395948e+00,\n",
       "        -1.76726958e-01, -8.06916072e-01,  8.59595099e-02,\n",
       "         3.86201616e-01,  2.26476744e-01, -8.88250681e-01,\n",
       "         2.32181251e+00, -9.47775456e-01],\n",
       "       [ 9.24674141e-01,  1.90442365e+00,  1.86614836e+00,\n",
       "         2.92185066e-01, -2.10334813e+00,  9.95132626e-02,\n",
       "         8.05300202e-01, -1.29296722e-01,  4.17003703e-01,\n",
       "         8.93038288e-01,  2.92937677e-01, -3.90793199e-02,\n",
       "         8.03416875e-01, -1.33112255e+00],\n",
       "       [ 3.85280892e-02,  3.81987944e-01, -4.33213013e-01,\n",
       "        -4.93233805e-01,  9.68523686e-01,  1.35509731e+00,\n",
       "         8.87961429e-01,  2.26997175e-01,  6.10112522e-01,\n",
       "         1.34139365e+00, -1.05341409e+00, -4.91783568e-01,\n",
       "         1.53110880e-01,  1.88613324e+00],\n",
       "       [ 3.04371905e-01, -6.64686602e-01, -4.33213013e-01,\n",
       "        -6.49505100e-01,  1.57413871e+00, -8.62562907e-01,\n",
       "         6.15867853e-01, -4.64294767e-01,  6.10112522e-01,\n",
       "         7.76076035e-01,  1.86195389e+00,  2.81479019e+00,\n",
       "         5.94382226e-01, -1.33112255e+00],\n",
       "       [ 2.15757299e-01,  9.65312493e-02, -4.33213013e-01,\n",
       "        -1.09310328e+00,  4.35401453e-01,  2.18274015e-01,\n",
       "        -9.36027625e-01, -2.47707731e-01,  4.44590564e-01,\n",
       "         7.43021528e-02, -3.95527129e-01, -9.27371259e-01,\n",
       "        -7.07064753e-01,  8.93380023e-01],\n",
       "       [ 7.47444930e-01, -9.37732136e-02,  7.16467676e-01,\n",
       "         3.72370717e-01, -9.97836853e-01,  8.93805484e-01,\n",
       "        -4.24197475e-01, -6.36393966e-03,  6.10112522e-01,\n",
       "        -1.21228323e+00, -8.85235886e-01,  1.23032308e-01,\n",
       "         3.13752057e+00, -1.10710622e+00],\n",
       "       [ 3.92986510e-01,  1.91683481e-01, -4.33213013e-01,\n",
       "        -1.04107618e+00,  2.51149581e-01,  1.14214886e-02,\n",
       "         1.05806934e+00, -1.33650292e+00,  1.13546418e-01,\n",
       "        -2.10899419e+00, -1.06358785e-01,  6.96558819e-01,\n",
       "        -1.84738072e-01, -4.28929127e-01],\n",
       "       [ 3.04371905e-01, -1.04529553e+00,  7.16467676e-01,\n",
       "        -2.50015640e-01,  2.26130798e+00,  4.33241765e-01,\n",
       "        -3.52594153e-01, -8.81406567e-02,  6.10112522e-01,\n",
       "         1.04898800e+00, -1.96624105e-01, -6.77200070e-01,\n",
       "        -7.45297295e-01, -4.16672914e-01],\n",
       "       [ 7.47444930e-01,  1.61896695e+00,  7.16467676e-01,\n",
       "        -1.64370640e-02,  1.79010621e+00,  1.88399465e+00,\n",
       "         3.91822109e-01,  1.58983726e+00, -4.10606362e-01,\n",
       "         7.76076035e-01, -5.22993720e-01, -5.77664411e-01,\n",
       "        -1.10524958e+00, -6.26045524e-02],\n",
       "       [ 4.81601115e-01, -1.88925445e-01, -4.33213013e-01,\n",
       "         1.88926652e+00,  3.26662516e-01, -1.55144203e+00,\n",
       "         7.59165368e-01, -4.49242605e-01,  4.44590564e-01,\n",
       "         9.32025586e-01, -9.47426578e-01,  6.29238796e-01,\n",
       "         7.59973205e-02,  4.77013605e-02],\n",
       "       [-1.46792020e+00, -1.42590445e+00,  7.16467676e-01,\n",
       "        -3.20186579e-01, -1.94024015e+00,  2.63259802e-02,\n",
       "         3.37056315e-01,  8.93584954e-01,  4.17003703e-01,\n",
       "         5.03164066e-01, -9.42648677e-01, -8.42702255e-01,\n",
       "         1.08770598e-01, -4.16672914e-01],\n",
       "       [-1.37930559e+00, -3.04349239e+00,  7.16467676e-01,\n",
       "         1.57879028e-01, -3.30301201e-01, -8.41686055e-02,\n",
       "        -1.50014534e+00,  2.03956910e+00,  8.59595099e-02,\n",
       "        -2.49886851e+00,  1.27326583e+00,  8.92273454e-01,\n",
       "         2.56185263e-01,  7.90227922e-02],\n",
       "       [-8.47617962e-01, -2.28227454e+00, -4.33213013e-01,\n",
       "         2.06599474e+00, -1.73233985e-01,  9.92852629e-01,\n",
       "        -3.36077878e-01,  2.13873527e+00,  8.59595099e-02,\n",
       "         8.15063332e-01, -1.07812415e-01, -9.56555043e-01,\n",
       "        -4.92996203e-01, -6.26045524e-02],\n",
       "       [-4.93159542e-01, -1.71136115e+00, -4.33213013e-01,\n",
       "        -1.26751852e-01,  5.50181489e-01,  9.96101951e-01,\n",
       "         6.97210075e-01,  7.67574159e-02, -3.22448103e+00,\n",
       "         6.20126320e-01,  1.26297214e+00,  5.08115850e-01,\n",
       "         7.56663479e-01,  1.83881499e-01],\n",
       "       [ 3.85280892e-02, -3.79229908e-01,  7.16467676e-01,\n",
       "        -1.10022799e+00,  1.01633633e-01, -1.19142481e+00,\n",
       "        -9.36544055e-01, -1.40830582e-02,  6.10112522e-01,\n",
       "         5.42151331e-01, -2.39618386e-01,  5.88428107e-02,\n",
       "        -9.47382962e-01, -1.40806433e+00],\n",
       "       [-7.59003357e-01, -6.64686602e-01,  1.86614836e+00,\n",
       "        -1.38505796e+00,  2.59507573e+00,  8.57702207e-01,\n",
       "         1.44562975e-01, -2.49086997e-01,  6.10112522e-01,\n",
       "         3.47214122e-01,  5.50884528e-01, -4.41512686e-01,\n",
       "        -3.61919256e-02,  1.92017827e+00],\n",
       "       [ 5.70215720e-01, -1.14044776e+00, -4.33213013e-01,\n",
       "         6.61811474e-02,  1.60533842e-01,  5.20518835e-02,\n",
       "        -8.94532485e-01, -8.92817169e-01, -1.29339075e+00,\n",
       "        -4.71521916e-01, -5.01395068e-01,  1.46014878e+00,\n",
       "        -1.52712187e+00,  6.45532170e-01],\n",
       "       [ 1.27142694e-01,  1.91683481e-01, -4.33213013e-01,\n",
       "         1.07251584e-01, -1.17000657e+00, -9.63328096e-01,\n",
       "        -1.86627595e+00, -1.95680545e+00, -5.76128551e-01,\n",
       "        -5.49496871e-01, -2.35460643e-01, -6.29834317e-02,\n",
       "         7.65310035e-01, -1.22898744e+00],\n",
       "       [ 3.85280892e-02,  7.62596869e-01,  7.16467676e-01,\n",
       "        -7.82946236e-01, -9.38936650e-01,  7.71221133e-01,\n",
       "        -1.17027254e-01, -1.33595677e+00, -1.29339075e+00,\n",
       "        -1.64114498e+00,  9.18653104e-03, -8.58033010e-01,\n",
       "         5.20527440e-01, -1.17791989e+00],\n",
       "       [-9.36232567e-01, -1.33075222e+00,  7.16467676e-01,\n",
       "        -1.73044148e-01, -2.50257116e-01,  8.38202518e-01,\n",
       "        -3.66924973e-01, -1.01782221e+00,  6.10112522e-01,\n",
       "        -1.98609914e-01, -3.74649529e-01, -8.29125973e-01,\n",
       "         7.28777525e-01, -5.31064230e-01],\n",
       "       [ 3.92986510e-01,  1.33351026e+00, -4.33213013e-01,\n",
       "         9.26149407e-01, -1.92060670e+00, -6.15156782e-01,\n",
       "         2.10938209e+00, -8.73840758e-01, -1.54167380e+00,\n",
       "        -1.09532094e+00,  1.60010798e+00,  1.77860101e+00,\n",
       "        -4.44159609e-02, -1.35495407e+00],\n",
       "       [ 3.92986510e-01,  6.67444638e-01,  7.16467676e-01,\n",
       "         5.98479088e-02,  1.29927120e+00, -8.12659299e-02,\n",
       "         8.07806771e-01,  9.12699568e-01,  4.17003703e-01,\n",
       "         1.04898800e+00, -6.83976757e-01, -5.64238443e-01,\n",
       "        -8.49907436e-01,  1.60151675e+00],\n",
       "       [ 1.01328875e+00,  6.67444638e-01,  7.16467676e-01,\n",
       "         9.16767103e-01, -1.92867379e-01, -2.83408991e-01,\n",
       "         5.99200100e-01,  2.20958471e+00,  4.44590564e-01,\n",
       "         8.93038288e-01, -1.81108005e-01, -7.68225907e-01,\n",
       "        -5.33401523e-01,  2.20650137e-01],\n",
       "       [ 1.36774717e+00, -8.54991065e-01, -4.33213013e-01,\n",
       "        -2.04850687e-01,  1.06367035e+00,  5.76723947e-01,\n",
       "         3.07207154e-01, -7.84124518e-01,  6.10112522e-01,\n",
       "         8.93038288e-01, -7.46777854e-01, -3.40068905e-01,\n",
       "         2.87197669e-01,  1.00096233e+00],\n",
       "       [ 3.85280892e-02, -8.54991065e-01,  7.16467676e-01,\n",
       "        -7.49827374e-01, -1.48460820e-01,  1.58553654e-01,\n",
       "        -6.85112426e-01, -6.60853679e-01,  6.10112522e-01,\n",
       "         1.57531832e+00, -5.81015676e-01, -3.78323907e-02,\n",
       "         4.25103009e-01,  4.77013605e-02],\n",
       "       [-9.36232567e-01, -9.37732136e-02,  7.16467676e-01,\n",
       "        -5.92070438e-01, -1.73233985e-01,  4.08528995e-01,\n",
       "        -1.01853624e-01,  8.21952093e-01,  4.44590564e-01,\n",
       "         7.43021528e-02,  2.37033050e+00,  1.16739680e+00,\n",
       "         5.38035047e-01, -1.26643698e+00],\n",
       "       [-8.47617962e-01,  7.62596869e-01, -4.33213013e-01,\n",
       "        -6.26376458e-01, -7.62236040e-01,  6.53476659e-01,\n",
       "        -9.33095607e-01, -6.83579865e-01, -2.17497497e-01,\n",
       "        -1.17329573e+00, -5.82259938e-01, -4.06409643e-01,\n",
       "         1.48507392e+00, -7.35334439e-01],\n",
       "       [ 7.47444930e-01, -2.84077676e-01, -1.58289370e+00,\n",
       "         1.52373512e+00, -7.42602657e-01,  2.50455939e-01,\n",
       "         1.07641605e+00, -1.12613992e+00,  6.10112522e-01,\n",
       "        -1.01734605e+00, -1.37578544e-01,  9.62212735e-01,\n",
       "        -5.34103273e-01, -1.33418225e-01],\n",
       "       [ 1.36774717e+00,  9.65312493e-02,  7.16467676e-01,\n",
       "         2.26767285e-01, -6.83702453e-01, -1.63208494e+00,\n",
       "        -1.12337544e+00,  2.47679656e-01,  6.10112522e-01,\n",
       "         1.32190020e+00, -3.68301512e-01, -3.74670851e-01,\n",
       "        -8.50722570e-01, -6.64520767e-01],\n",
       "       [ 5.70215720e-01,  5.72292406e-01, -1.58289370e+00,\n",
       "         1.14071972e+00, -1.53600591e-01,  1.21272580e+00,\n",
       "         7.58543115e-01, -2.58628739e-01, -4.10606362e-01,\n",
       "         3.08226660e-01,  3.52088045e-01,  7.63845657e-01,\n",
       "         5.94382226e-01,  6.80939007e-01],\n",
       "       [ 3.92986510e-01,  1.37901785e-03,  7.16467676e-01,\n",
       "         6.90302678e-01,  4.39932355e-01, -3.94791420e-01,\n",
       "        -2.72362016e+00, -5.19767508e-01,  2.51481745e-01,\n",
       "         7.76076035e-01,  5.19935216e-01,  9.59900634e-02,\n",
       "        -3.20458104e-01, -1.22523814e-01],\n",
       "       [-1.46792020e+00,  9.65312493e-02,  7.16467676e-01,\n",
       "         4.27878994e-01,  2.97967642e-01, -1.00152835e+00,\n",
       "         2.03114269e-01,  3.90816968e-01, -4.21761323e+00,\n",
       "        -1.48519525e+00, -9.59830923e-01, -9.05690981e-01,\n",
       "         3.43711702e-01,  1.38907573e+00],\n",
       "       [ 3.85280892e-02,  8.57749101e-01,  7.16467676e-01,\n",
       "         1.14170474e+00, -6.83702453e-01, -2.46304968e-01,\n",
       "         1.12272243e+00, -1.39670014e+00,  6.10112522e-01,\n",
       "         7.76076035e-01, -5.16523763e-01, -6.12207885e-01,\n",
       "        -6.56733825e-01, -1.23103015e+00],\n",
       "       [ 5.70215720e-01, -2.84077676e-01, -4.33213013e-01,\n",
       "        -9.15579213e-01,  1.06367035e+00,  3.50956954e-01,\n",
       "        -4.92236178e-01, -8.49023313e-01, -9.07172466e-01,\n",
       "         1.04898800e+00, -6.40239404e-01,  7.60623868e-01,\n",
       "        -1.68182442e+00,  1.49836464e-01],\n",
       "       [ 4.81601115e-01, -9.37732136e-02,  1.86614836e+00,\n",
       "         6.90302678e-01, -5.26635227e-01, -1.42028988e+00,\n",
       "         8.55986564e-01, -7.60971711e-01,  2.51481745e-01,\n",
       "        -4.26601990e-02, -3.95733928e-01, -4.35656713e-01,\n",
       "         3.11007933e-01, -1.56739509e+00],\n",
       "       [ 1.98804940e+00,  9.52901332e-01, -4.33213013e-01,\n",
       "        -5.01333338e-01,  1.04978532e-01, -1.40230091e+00,\n",
       "         1.16635035e+00, -2.91140794e-01,  2.79068375e-01,\n",
       "        -2.49886851e+00, -7.66631941e-01, -9.75966580e-01,\n",
       "        -7.85915699e-01,  2.15448822e+00]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47628676",
   "metadata": {},
   "source": [
    "## LOOCV with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "feb2d55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.043 (0.064)\n"
     ]
    }
   ],
   "source": [
    "# find number of samples\n",
    "n = X.shape[0]\n",
    "# create loocv procedure\n",
    "cv = LeaveOneOut()\n",
    "# create model\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'linear')\n",
    "# evaluate model\n",
    "scores = cross_val_score(regressor, X, y, scoring='neg_mean_squared_error', cv=n)\n",
    "# force positive\n",
    "#scores = absolute(scores)\n",
    "\n",
    "# report performance\n",
    "print('MSE: %.3f (%.3f)' % (mean(scores), std(scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d145ebe",
   "metadata": {},
   "source": [
    "## Find the best predictors using RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "226c925d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.039 (0.062)\n"
     ]
    }
   ],
   "source": [
    "# explore the algorithm wrapped by RFE\n",
    "# automatically select the number of features for RFE\n",
    "\n",
    "# create pipeline\n",
    "rfe = RFECV(estimator=SVR(kernel = 'linear'),min_features_to_select=2)\n",
    "model = SVR(kernel = 'linear')\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "# find number of samples\n",
    "n = X.shape[0]\n",
    "# create loocv procedure\n",
    "cv = LeaveOneOut()\n",
    "# evaluate model\n",
    "#rfe.fit(X,y)\n",
    "scores = cross_val_score(pipeline, X, y, scoring='neg_mean_squared_error', cv=n)\n",
    "# report performance\n",
    "print('MSE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ec198",
   "metadata": {},
   "source": [
    "### Predicting the best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "14c12fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected True,\t Rank: 1.0, \tName: T_Vocab\n",
      "Selected False,\t Rank: 4.0, \tName: T_Matrix\n",
      "Selected False,\t Rank: 5.0, \tName: Corsi_WM_Span\n",
      "Selected False,\t Rank: 10.0, \tName: CogFlex_t\n",
      "Selected False,\t Rank: 11.0, \tName: SSRT\n",
      "Selected False,\t Rank: 2.0, \tName: FlankerSwitch_t\n",
      "Selected True,\t Rank: 1.0, \tName: FlankerInhib_t\n",
      "Selected True,\t Rank: 1.0, \tName: Stroop_t\n",
      "Selected False,\t Rank: 7.0, \tName: dprimeONEBACK_t0\n",
      "Selected False,\t Rank: 6.0, \tName: dprimeTWOBACK_t0\n",
      "Selected False,\t Rank: 8.0, \tName: AY_Inv_eff_score\n",
      "Selected False,\t Rank: 12.0, \tName: BX_Inv_eff_score\n",
      "Selected False,\t Rank: 3.0, \tName: CF_Mix_IES_Diff\n",
      "Selected False,\t Rank: 9.0, \tName: SSRT_SSD_z\n"
     ]
    }
   ],
   "source": [
    "# find out which predictors\n",
    "rfe.fit(X,y)\n",
    "\n",
    "data_top = X_cols.columns\n",
    "# summarise all features\n",
    "for i in range(X.shape[1]):\n",
    "    print('Selected %s,\\t Rank: %.1f, \\tName: %s' % (rfe.support_[i], rfe.ranking_[i],data_top[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc0644",
   "metadata": {},
   "source": [
    "## Use permutation testing to find the best predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf84ef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claire.smid\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classifier=False as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1543\n",
       "                \n",
       "                    &plusmn; 0.5425\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                FlankerInhib_t\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 81.41%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.1390\n",
       "                \n",
       "                    &plusmn; 0.4667\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Stroop_t\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.76%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0512\n",
       "                \n",
       "                    &plusmn; 0.3807\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SSRT_SSD_z\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.20%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0478\n",
       "                \n",
       "                    &plusmn; 0.2653\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                dprimeTWOBACK_t0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.38%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0318\n",
       "                \n",
       "                    &plusmn; 0.3323\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                FlankerSwitch_t\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.72%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0295\n",
       "                \n",
       "                    &plusmn; 0.2809\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CogFlex_t\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0144\n",
       "                \n",
       "                    &plusmn; 0.2389\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                dprimeONEBACK_t0\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.42%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0132\n",
       "                \n",
       "                    &plusmn; 0.2523\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                SSRT\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 97.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0065\n",
       "                \n",
       "                    &plusmn; 0.1575\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                T_Vocab\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 97.55%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0077\n",
       "                \n",
       "                    &plusmn; 0.1345\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                AY_Inv_eff_score\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 96.39%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0134\n",
       "                \n",
       "                    &plusmn; 0.1650\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                BX_Inv_eff_score\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 94.64%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0235\n",
       "                \n",
       "                    &plusmn; 0.1910\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                Corsi_WM_Span\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 94.32%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0255\n",
       "                \n",
       "                    &plusmn; 0.1966\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                T_Matrix\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 94.04%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0274\n",
       "                \n",
       "                    &plusmn; 0.2210\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                CF_Mix_IES_Diff\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5 import show_prediction, show_weights, explain_weights\n",
    "\n",
    "Xfeature_names = X_cols.columns\n",
    "\n",
    "# create pipeline\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=100, random_state=1)\n",
    "perm = PermutationImportance(regressor, cv = cv)\n",
    "perm.fit(X,y)\n",
    "\n",
    "show_weights(perm, feature_names = X_cols.columns.tolist())\n",
    "#explain_weights(perm, feature_names = X.columns.tolist())\n",
    "#show_prediction(perm, X.iloc[4], feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "07bd97c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00645255 -0.02552878 -0.02353879  0.02946203  0.01320793  0.03182114\n",
      "  0.15428623  0.13900219  0.01444998  0.04777883 -0.00768619 -0.01337976\n",
      " -0.02737885  0.05121387]\n",
      "Feature: 0, Score: 0.15429\n",
      "Feature: 1, Score: 0.13900\n",
      "Feature: 2, Score: 0.05121\n",
      "Feature: 3, Score: 0.04778\n",
      "Feature: 4, Score: 0.03182\n",
      "Feature: 5, Score: 0.02946\n",
      "Feature: 6, Score: 0.01445\n",
      "Feature: 7, Score: 0.01321\n",
      "Feature: 8, Score: -0.00645\n",
      "Feature: 9, Score: -0.00769\n",
      "Feature: 10, Score: -0.01338\n",
      "Feature: 11, Score: -0.02354\n",
      "Feature: 12, Score: -0.02553\n",
      "Feature: 13, Score: -0.02738\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = perm.feature_importances_\n",
    "names = X_cols.columns.tolist()\n",
    "#print(importance)\n",
    "print(importance)\n",
    "f_sorted = sorted(importance, reverse = True)\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(f_sorted):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(f_sorted))], f_sorted)\n",
    "plt.ylabel(\"Feature importance\")\n",
    "plt.tick_params(axis='x',bottom=False,labelbottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ed3538f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.07796\n",
      "Feature: 1, Score: 0.06074\n",
      "Feature: 2, Score: 0.07496\n",
      "Feature: 3, Score: 0.15183\n",
      "Feature: 4, Score: 0.14634\n",
      "Feature: 5, Score: 0.12535\n",
      "Feature: 6, Score: 0.25548\n",
      "Feature: 7, Score: 0.19084\n",
      "Feature: 8, Score: 0.04963\n",
      "Feature: 9, Score: 0.10259\n",
      "Feature: 10, Score: 0.04467\n",
      "Feature: 11, Score: 0.05160\n",
      "Feature: 12, Score: 0.04188\n",
      "Feature: 13, Score: 0.19839\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# create pipeline\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "\n",
    "regressor.fit(X,y)\n",
    "\n",
    "results = permutation_importance(regressor, X, y)\n",
    "importance = results.importances_mean\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29073c27",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64d088de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C', 'cache_size', 'coef0', 'degree', 'epsilon', 'gamma', 'kernel', 'max_iter', 'shrinking', 'tol', 'verbose'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff32882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MSE Score: -0.029412974676457725\n",
      "Best Hyperparameters {'C': 10, 'epsilon': 0.1, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': -1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# for metacontrol\n",
    "X = dataset[[\"Stroop_t\",\"FlankerInhib_t\"]]\n",
    "X_cols = X\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# find number of samples\n",
    "n = X.shape[0]\n",
    "\n",
    "# create loocv procedure\n",
    "cv = LeaveOneOut()\n",
    "# create model\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR()\n",
    "# define search space\n",
    "parameters = {'kernel': ['linear','rbf'], 'C':[0.1, 0.5, 1, 1.5, 2, 5, 10, 20],\n",
    "              'gamma': [1e-7, 1e-4, 1e3, 0.01, 0.1, 0.2],'epsilon':[0.1,0.2,0.5,0.3],\n",
    "             'max_iter': [-1]}\n",
    "\n",
    "search = GridSearchCV(regressor,parameters,scoring='neg_mean_squared_error',cv=cv, n_jobs = -1)\n",
    "\n",
    "# random search:\n",
    "#search = RandomizedSearchCV(regressor, parameters, n_iter=1000, \n",
    "                            #scoring='neg_mean_absolute_error', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(X,y)\n",
    "\n",
    "# summarize result\n",
    "print('Best MSE Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters %s' % result.best_params_ )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dd95b7",
   "metadata": {},
   "source": [
    "## K-fold cross validation with tuned model and best predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "27331954",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.030 (0.013)\n",
      "r2: 0.062 (0.327)\n",
      "exp var: 0.155\n"
     ]
    }
   ],
   "source": [
    "# explore the algorithm wrapped by RFE\n",
    "# automatically select the number of features for RFE\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# make the model manually with the predictors\n",
    "#X = dataset[[\"flankerinh_t0\"]]\n",
    "#X = dataset[[\"flankerinh_t0\",\"stroop_t0\"]]\n",
    "#X = dataset[[\"flankerinh_t0\",\"flankerswitch_t0\",\"dprimeONEBACK_t0\",\"dprimeTWOBACK_t0\",\n",
    "           # \"AXCPT_CorrRT_Shift_Index\",\"AY_RCS\",\"BX_RCS\",\"Stroop_InCon_IES_Diff\",\n",
    "           # \"SSRT_mean_ssd\",\"CF_Mix_IES_Diff\"]]\n",
    "\n",
    "# create pipeline\n",
    "#regressor = SVR(kernel = 'rbf', C = 10, epsilon = 0.1, gamma = 0.2)\n",
    "#regressor = SVR(kernel = 'linear', C = 1, epsilon = 0.5, gamma = 1e-07)\n",
    "#regressor = SVR(kernel = 'rbf', C = 0.5, epsilon = 0.1, gamma = 0.1, max_iter=-1)\n",
    "\n",
    "regressor = SVR(kernel = 'rbf', C = 10, epsilon = 0.1, gamma = 0.01, max_iter=-1)\n",
    "#regressor = SVR(kernel = 'sigmoid', C = 5, epsilon = 0.1, gamma = 0.2, max_iter=-1)\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=100, random_state=1)\n",
    "n_scores = cross_val_score(regressor, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "r2_scores = cross_val_score(regressor, X, y, scoring='r2', cv=cv, n_jobs=-1, error_score='raise')\n",
    "explained_var = cross_val_score(regressor, X, y, scoring='explained_variance', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('MSE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "print('r2: %.3f (%.3f)' % (mean(r2_scores), std(r2_scores)))\n",
    "print('exp var: %.3f' % mean(explained_var))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7428e",
   "metadata": {},
   "source": [
    "## new results:\n",
    "### rbf kernel (three predictors: flanker (2) and stroop) (7 jun data)\n",
    "- MSE: -0.030\n",
    "- r2: -0.144\n",
    "- exp var: -0.038\n",
    "\n",
    "### rbf kernel (two predictors: flanker and stroop) (7 jun data)\n",
    "- MSE: -0.030\n",
    "- r2: 0.062\n",
    "- exp var: 0.155\n",
    "\n",
    "### rbf kernel (two predictors: flanker and stroop)\n",
    "- MSE = -0.032\n",
    "- r2 = 0.046\n",
    "- exp var: 0.130\n",
    "\n",
    "## old results:\n",
    "\n",
    "### linear kernel \n",
    "- MSE: -0.034\n",
    "- r2 = 0.022\n",
    "- exp var= 0.152\n",
    "\n",
    "### rbf kernel (two predictors: flanker and stroop)\n",
    "- MSE = -0.031\n",
    "- r2 = 0.104\n",
    "- exp var = 0.203\n",
    "\n",
    "### rbf kernel (one predictor: flanker)\n",
    "- MSE = -0.034\n",
    "- r2 = 0.016\n",
    "- exp var = 0.157"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e01a2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claire.smid\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classifier=False as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "show_prediction() missing 1 required positional argument: 'doc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-ee01e22ae289>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mshow_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_cols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mshow_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_cols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: show_prediction() missing 1 required positional argument: 'doc'"
     ]
    }
   ],
   "source": [
    "#X = dataset[[\"flankerinh_t0\",\"stroop_t0\"]]\n",
    "Xfeature_names = X_cols.columns\n",
    "\n",
    "# create pipeline\n",
    "regressor = SVR(kernel = 'rbf', C = 10, epsilon = 0.1, gamma = 0.01, max_iter=-1)\n",
    "\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=100, random_state=1)\n",
    "perm = PermutationImportance(regressor, cv = cv)\n",
    "perm.fit(X,y)\n",
    "\n",
    "show_weights(perm, feature_names = X_cols.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d1adad06",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVR' object has no attribute 'predict_proba'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-5290b4a2d2c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimportance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mperm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimportance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mperm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, type)\u001b[0m\n\u001b[0;32m    112\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                     \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVR' object has no attribute 'predict_proba'"
     ]
    }
   ],
   "source": [
    "importance = perm.feature_importances_\n",
    "importance\n",
    "perm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49662349",
   "metadata": {},
   "source": [
    "## Repeat with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cef4549a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-949ce5f67f59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mpc_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    395\u001b[0m                             'TruncatedSVD for a possible alternative.')\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 397\u001b[1;33m         X = self._validate_data(X, dtype=[np.float64, np.float32],\n\u001b[0m\u001b[0;32m    398\u001b[0m                                 ensure_2d=True, copy=self.copy)\n\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'no_validation'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 0.85)\n",
    "\n",
    "# from column 8 onwards no more model parameters, or maybe just include all?\n",
    "# now including only the EFs for the first approach, and splitting factors for the later approach\n",
    "X = dataset.iloc[:, np.r_[14:34]]\n",
    "X_cols = X\n",
    "y = dataset.iloc[:,8]\n",
    "\n",
    "pca.fit(X)\n",
    "pc_X = pca.transform(X)\n",
    "\n",
    "# find number of sam`aples\n",
    "n = pc_X.shape[0]\n",
    "# create loocv procedure\n",
    "cv = LeaveOneOut()\n",
    "# create model\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "# evaluate model\n",
    "scores = cross_val_score(regressor, pc_X, y, scoring='neg_mean_squared_error', cv=n)\n",
    "# force positive\n",
    "#scores = absolute(scores)\n",
    "\n",
    "# report performance\n",
    "print('MSE: %.3f (%.3f)' % (mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "613e79a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-506.436158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-869.730993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>548.839333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>829.517722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-180.606737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-773.641050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-770.911363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-643.700990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-449.336181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1204.021282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0   -506.436158\n",
       "1   -869.730993\n",
       "2    548.839333\n",
       "3    829.517722\n",
       "4   -180.606737\n",
       "..          ...\n",
       "64  -773.641050\n",
       "65  -770.911363\n",
       "66  -643.700990\n",
       "67  -449.336181\n",
       "68  1204.021282\n",
       "\n",
       "[69 rows x 1 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "principalDF = pd.DataFrame(data = pc_X)\n",
    "principalDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbcce8a",
   "metadata": {},
   "source": [
    "## Then run rfe again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6838f41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.041 (0.018)\n",
      "r2: -0.220 (0.254)\n",
      "exp var: -0.102\n"
     ]
    }
   ],
   "source": [
    "# explore the algorithm wrapped by RFE\n",
    "# automatically select the number of features for RFE\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# create pipeline\n",
    "rfe = RFECV(estimator=SVR(kernel = 'rbf'),min_features_to_select=1)\n",
    "model = SVR(kernel = 'rbf')\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model)])\n",
    "\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(regressor, pc_X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "r2_scores = cross_val_score(regressor, pc_X, y, scoring='r2', cv=cv, n_jobs=-1, error_score='raise')\n",
    "explained_var = cross_val_score(regressor, pc_X, y, scoring='explained_variance', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('MSE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "print('r2: %.3f (%.3f)' % (mean(r2_scores), std(r2_scores)))\n",
    "print('exp var: %.3f' % mean(explained_var))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18e15bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # find out which predictors\n",
    "# rfe.fit(pc_X,y)\n",
    "# data_top=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10']\n",
    "# # data_top = ['MemSpeed_negBXRCS','posBXRCS_MemSpeed','PBI_InConIES',\n",
    "# #                                                    'negSwitchIES_negPBI','DP2_negCFSwitchIES',\n",
    "# #                                                    'negCFSwitchIES_InconIES','negInConIES_AYRCS']\n",
    "# # summarise all features\n",
    "# for i in range(pc_X.shape[1]):\n",
    "#     print('row: %d, Selected %s,\\t Rank: %.1f, \\tName: %s' % (i, rfe.support_[i], rfe.ranking_[i],data_top[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10c4818",
   "metadata": {},
   "source": [
    "## Then run permutation testing again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7eb79653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claire.smid\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classifier=False as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                -0.0181\n",
       "                \n",
       "                    &plusmn; 0.5289\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                PC1\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from eli5 import show_prediction, show_weights\n",
    "\n",
    "#data_top=['PC1','PC2','PC3','PC4','PC5','PC6','PC7','PC8','PC9','PC10']\n",
    "data_top=['PC1']\n",
    "Xfeature_names = data_top\n",
    "\n",
    "# create pipeline\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=10, random_state=1)\n",
    "perm = PermutationImportance(regressor, cv = cv)\n",
    "perm.fit(pc_X,y)\n",
    "\n",
    "show_weights(perm, feature_names = Xfeature_names)\n",
    "#show_prediction(perm, X.iloc[4], feature_names = X.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079e20ce",
   "metadata": {},
   "source": [
    "## Hyper parameter testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5907208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# if only one variable\n",
    "#var = pc_X[:,5]\n",
    "var = pc_X\n",
    "X = var.reshape(len(var),1)\n",
    "\n",
    "# if more than 1\n",
    "#X = pc_X[:,[5,9]]\n",
    "\n",
    "# find number of samples\n",
    "n = X.shape[0]\n",
    "\n",
    "# create loocv procedure\n",
    "cv = LeaveOneOut()\n",
    "# create model\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'linear')\n",
    "# define search space\n",
    "#space = dict()\n",
    "#space['solver'] = ['svd', 'cholesky', 'lsqr', 'sag']\n",
    "#space['alpha'] =  [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
    "#space['fit_intercept'] = [True, False]\n",
    "#space['normalize'] = [True, False]\n",
    "parameters = {'kernel': ['linear','rbf'], 'C':[1.5, 10],'gamma': [1e-7, 1e-4, 1e-3, 0.01, 0.1, 0.2],'epsilon':[0.1,0.2,0.5,0.3]}\n",
    "#parameters = {'kernel': ('linear', 'rbf'), 'C':[1.5, 10],'gamma': [1e-7, 1e-4],'epsilon':[0.1,0.2,0.5,0.3]}\n",
    "#space['parameters'] = {'kernel':('linear','rbf'), 'C':[1.5]}\n",
    "# define search\n",
    "search = GridSearchCV(regressor,parameters,scoring='neg_mean_squared_error',cv=cv, n_jobs = -1)\n",
    "# execute search\n",
    "result = search.fit(X,y)\n",
    "\n",
    "# evaluate model\n",
    "#scores = cross_val_score(regressor, X, y, scoring='neg_mean_squared_error', cv=n)\n",
    "# force positive\n",
    "#scores = absolute(scores)\n",
    "\n",
    "# summarize result\n",
    "print('Best MSE Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters %s' % result.best_params_ )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd4357",
   "metadata": {},
   "source": [
    "## Then use k-fold cross validation again to test final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b36d616b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: -0.039 (0.016)\n",
      "r2: -0.113 (0.143)\n",
      "exp var: 0.015\n"
     ]
    }
   ],
   "source": [
    "# explore the algorithm wrapped by RFE\n",
    "# automatically select the number of features for RFE\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "\n",
    "# create pipeline\n",
    "regressor = SVR(kernel = 'rbf', C = 10, epsilon = 0.1, gamma = 0.0001)\n",
    "#regressor = SVR(kernel = 'linear', C = 1, epsilon = 0.5, gamma = 1e-07)\n",
    "# evaluate model\n",
    "cv = RepeatedKFold(n_splits=6, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(regressor, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "r2_scores = cross_val_score(regressor, X, y, scoring='r2', cv=cv, n_jobs=-1, error_score='raise')\n",
    "explained_var = cross_val_score(regressor, X, y, scoring='explained_variance', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# report performance\n",
    "print('MSE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n",
    "print('r2: %.3f (%.3f)' % (mean(r2_scores), std(r2_scores)))\n",
    "print('exp var: %.3f' % mean(explained_var))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ca57c",
   "metadata": {},
   "source": [
    "### for one predictor (PC4)\n",
    "- MSE -0.039\n",
    "- r2 -0.113\n",
    "- exp var 0.015\n",
    "\n",
    "### for two predictor (PC4 and 8)\n",
    "- MSE -0.040\n",
    "- r2 = -0.126\n",
    "- exp var = 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5ed6f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
